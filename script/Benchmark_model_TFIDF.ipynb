{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import numpy\n",
    "import itertools\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(data):\n",
    "    \n",
    "    tokenizer = Tokenizer(lower = True, char_level=False)   \n",
    "    question_list = data.loc[:,'wordlist_1_clean'].values.tolist()\n",
    "    question_list += data.loc[:,'wordlist_2_clean'].values.tolist()\n",
    "    \n",
    "    question_list = [i.encode('ascii', 'ignore') for i in question_list]\n",
    "    tokenizer.fit_on_texts(question_list)\n",
    "    \n",
    "    word_list = tokenizer.word_index.keys()\n",
    "    f = open('wordlist_clean_tfidf.txt', 'w')\n",
    "    for item in word_list:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "    \n",
    "    print(len(word_list))\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def write_sequence(data,tokenizer,question_list):\n",
    "    wordlist = [i.encode('ascii', 'ignore')  for i in data.loc[:,'wordlist_'+question_list+'_clean'].values.tolist()]  \n",
    "    sequences = tokenizer.texts_to_matrix(wordlist,mode = \"tfidf\")\n",
    "    wordlist = 0\n",
    "    print('finished sequencing')\n",
    "    numpy.savetxt('../input/data_q'+question_list+'_clean_tfidf.csv', sequences , delimiter=\",\",fmt = '%.6e')\n",
    "\n",
    "\n",
    "def get_tfidf(data): \n",
    "   \n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    #### Tokenizing Words to sequences.\n",
    "    data_tokenizer = get_tokenizer(data)   \n",
    "    current = timeit.default_timer()\n",
    "    print('Time to tokenize [s]= ',current - start)\n",
    "\n",
    "    write_sequence(data,data_tokenizer,question_list = '1')\n",
    "    current = timeit.default_timer()\n",
    "    print('Time to sequence q1 [s]= ',current - start)\n",
    "\n",
    "    write_sequence(data,data_tokenizer,question_list = '2')\n",
    "    current = timeit.default_timer()\n",
    "    print('Time to sequence q2 [s]= ',current - start)\n",
    "    \n",
    "    data =  data.loc[:,['is_duplicate']]\n",
    "    \n",
    "    with open('../input/data_q1_clean_tfidf.csv', 'rb') as q1:\n",
    "        print('q1')\n",
    "        with open('../input/data_q2_clean_tfidf.csv', 'rb') as q2:\n",
    "            print('q2')\n",
    "            reader1 = csv.reader(q1, delimiter=\",\")\n",
    "            reader2 = csv.reader(q2, delimiter=\",\")\n",
    "            print('readers')\n",
    "            i = 0\n",
    "            for line in itertools.izip(reader1,reader2):\n",
    "                if i%100 == 0:\n",
    "                    print(i, end=',')\n",
    "                \n",
    "                seq_1 = [float(j) for j in line[0]]\n",
    "                seq_2 = [float(j) for j in line[1]]\n",
    "                                \n",
    "                try:\n",
    "                    cosine = cosine_similarity(np.array(seq_1).reshape(1, -1), np.array(seq_2).reshape(1, -1))\n",
    "                except:\n",
    "                    cosine = [[0]]\n",
    "                data.loc[data.index[0]+i,('cosine_tfidf')] = cosine[0][0] \n",
    "                i += 1\n",
    "\n",
    "                \n",
    "    data.to_csv('../input/data_clean_tfidf.csv', encoding=\"utf-8\")\n",
    "    \n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_benchmark_results():\n",
    "    \n",
    "    data = pd.read_csv('../input/data_clean_tfidf.csv', \n",
    "                       nrows = 1)\n",
    "    column_names = data.columns.tolist()\n",
    "    print(column_names)\n",
    "    print(data.loc[0])\n",
    "    \n",
    "    data = pd.read_csv('../input/data_clean_tfidf.csv', usecols = ['cosine_tfidf','is_duplicate'])\n",
    "    data = data.fillna('')\n",
    "    print(data.loc[0])\n",
    "    print(len(data[['cosine_tfidf']]))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.loc[:,('cosine_tfidf')].values.reshape(-1, 1), data.loc[:,('is_duplicate')], test_size=0.30, random_state=42)\n",
    "    benchmark_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "def benchmark_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "# fit logistic_regression to find threshold \n",
    "# check test data to find accuracy and fscore\n",
    "\n",
    "    clf = linear_model.LogisticRegression(random_state=42,solver = 'lbfgs',class_weight = 'balanced')\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune\n",
    "    parameters = {'C':[1e-18,1e-17,1e-16,1e-15,1e-14,1e-13,1e-12,1e-11,1e-9,1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1,10]}\n",
    "\n",
    "# TODO: Make an f1_score scoring object\n",
    "    scorer = make_scorer(log_loss,needs_proba = True, greater_is_better = False)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "    grid_obj = GridSearchCV(clf, parameters,scoring=scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "    grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "    best_clf = grid_fit.best_estimator_\n",
    "\n",
    "#    print(grid_fit.cv_results_)\n",
    "    print(grid_fit.best_params_)\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "    predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "    predictions_proba =(clf.fit(X_train, y_train)).predict_proba(X_test)\n",
    "    best_predictions = best_clf.predict(X_test)\n",
    "    best_predictions_proba = best_clf.predict_proba(X_test)\n",
    "    \n",
    "    print(best_clf.coef_)\n",
    "    print(best_clf.intercept_)\n",
    "    print([0.6,0.53,0.52,0.5],best_clf.predict(np.asarray([0.6,0.53,0.52,0.5]).reshape(-1, 1)))\n",
    "    \n",
    " #   print(max(best_predictions))\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "    print(\"Unoptimized model\\n------\")\n",
    "    print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(\"Log-loss on testing data: {:.4f}\".format(log_loss(y_test, predictions_proba)))\n",
    "    print(\"\\nOptimized Model\\n------\")\n",
    "    print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "    print(\"Final Log-loss on the testing data: {:.4f}\".format(log_loss(y_test, best_predictions_proba)))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                                              0\n",
      "id                                                                      0\n",
      "qid1                                                                    1\n",
      "qid2                                                                    2\n",
      "question1               What is the step by step guide to invest in sh...\n",
      "question2               What is the step by step guide to invest in sh...\n",
      "is_duplicate                                                            0\n",
      "wordlist_1_clean        What is the step by step guide to invest in sh...\n",
      "len_q1_clean                                                           66\n",
      "wordlist_1_stopwords            step step guide invest share market india\n",
      "len_q1_stopwords                                                       41\n",
      "wordlist_1_stem                  step step guid invest share market india\n",
      "wordlist_2_clean        What is the step by step guide to invest in sh...\n",
      "len_q2_clean                                                           57\n",
      "wordlist_2_stopwords                  step step guide invest share market\n",
      "len_q2_stopwords                                                       35\n",
      "wordlist_2_stem                        step step guid invest share market\n",
      "Name: 0, dtype: object\n",
      "Time to read data_clean.csv [s]=  5.23400497437\n",
      "33298\n",
      "Time to tokenize [s]=  2.89177799225\n",
      "finished sequencing\n",
      "Time to sequence q1 [s]=  625.821553946\n",
      "finished sequencing\n",
      "Time to sequence q2 [s]=  1313.98070908\n",
      "q1\n",
      "q2\n",
      "readers\n",
      "0,100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,5000,5100,5200,5300,5400,5500,5600,5700,5800,5900,6000,6100,6200,6300,6400,6500,6600,6700,6800,6900,7000,7100,7200,7300,7400,7500,7600,7700,7800,7900,8000,8100,8200,8300,8400,8500,8600,8700,8800,8900,9000,9100,9200,9300,9400,9500,9600,9700,9800,9900,10000,10100,10200,10300,10400,10500,10600,10700,10800,10900,11000,11100,11200,11300,11400,11500,11600,11700,11800,11900,12000,12100,12200,12300,12400,12500,12600,12700,12800,12900,13000,13100,13200,13300,13400,13500,13600,13700,13800,13900,14000,14100,14200,14300,14400,14500,14600,14700,14800,14900,15000,15100,15200,15300,15400,15500,15600,15700,15800,15900,16000,16100,16200,16300,16400,16500,16600,16700,16800,16900,17000,17100,17200,17300,17400,17500,17600,17700,17800,17900,18000,18100,18200,18300,18400,18500,18600,18700,18800,18900,19000,19100,19200,19300,19400,19500,19600,19700,19800,19900,20000,20100,20200,20300,20400,20500,20600,20700,20800,20900,21000,21100,21200,21300,21400,21500,21600,21700,21800,21900,22000,22100,22200,22300,22400,22500,22600,22700,22800,22900,23000,23100,23200,23300,23400,23500,23600,23700,23800,23900,24000,24100,24200,24300,24400,24500,24600,24700,24800,24900,25000,25100,25200,25300,25400,25500,25600,25700,25800,25900,26000,26100,26200,26300,26400,26500,26600,26700,26800,26900,27000,27100,27200,27300,27400,27500,27600,27700,27800,27900,28000,28100,28200,28300,28400,28500,28600,28700,28800,28900,29000,29100,29200,29300,29400,29500,29600,29700,29800,29900,30000,30100,30200,30300,30400,30500,30600,30700,30800,30900,31000,31100,31200,31300,31400,31500,31600,31700,31800,31900,32000,32100,32200,32300,32400,32500,32600,32700,32800,32900,33000,33100,33200,33300,33400,33500,33600,33700,33800,33900,34000,34100,34200,34300,34400,34500,34600,34700,34800,34900,35000,35100,35200,35300,35400,35500,35600,35700,35800,35900,36000,36100,36200,36300,36400,36500,36600,36700,36800,36900,37000,37100,37200,37300,37400,37500,37600,37700,37800,37900,38000,38100,38200,38300,38400,38500,38600,38700,38800,38900,39000,39100,39200,39300,39400,39500,39600,39700,39800,39900,40000,40100,40200,40300,40400,40500,40600,40700,40800,40900,41000,41100,41200,41300,41400,41500,41600,41700,41800,41900,42000,42100,42200,42300,42400,42500,42600,42700,42800,42900,43000,43100,43200,43300,43400,43500,43600,43700,43800,43900,44000,44100,44200,44300,44400,44500,44600,44700,44800,44900,45000,45100,45200,45300,45400,45500,45600,45700,45800,45900,46000,46100,46200,46300,46400,46500,46600,46700,46800,46900,47000,47100,47200,47300,47400,47500,47600,47700,47800,47900,48000,48100,48200,48300,48400,48500,48600,48700,48800,48900,49000,49100,49200,49300,49400,49500,49600,49700,49800,49900,Time to get tfidf [s]=  2605.16234708\n",
      "['Unnamed: 0', 'is_duplicate', 'cosine_tfidf']\n",
      "Unnamed: 0      0.000000\n",
      "is_duplicate    0.000000\n",
      "cosine_tfidf    0.982595\n",
      "Name: 0, dtype: float64\n",
      "is_duplicate    0.000000\n",
      "cosine_tfidf    0.982595\n",
      "Name: 0, dtype: float64\n",
      "50000\n",
      "{'C': 0.1}\n",
      "[[ 3.53202711]]\n",
      "[-1.84202444]\n",
      "[0.6, 0.53, 0.52, 0.5] [1 1 0 0]\n",
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.6651\n",
      "Log-loss on testing data: 0.6009\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.6652\n",
      "Final Log-loss on the testing data: 0.6008\n",
      "Time to get tfidf benchmark results [s]=  2608.48285294\n"
     ]
    }
   ],
   "source": [
    "def main(n=100):\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    data = pd.read_csv('../input/data_clean.csv', encoding=\"utf-8\")\n",
    "    data = data.fillna('')\n",
    "    data = data.head(n=n).copy()\n",
    "##    data = data[(data.id >= 105790) & (data.id <= (105790+n))].copy()\n",
    "    print(data.loc[data.index[0]])\n",
    "    current = timeit.default_timer()\n",
    "    print('Time to read data_clean.csv [s]= ',current - start)\n",
    "\n",
    "    get_tfidf(data)\n",
    "    current = timeit.default_timer()\n",
    "    print('Time to get tfidf [s]= ',current - start)\n",
    "\n",
    "    get_benchmark_results()\n",
    "    current = timeit.default_timer()\n",
    "    print('Time to get tfidf benchmark results [s]= ',current - start)\n",
    "\n",
    "    \n",
    "main(n=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
